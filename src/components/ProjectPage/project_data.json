[
  {
    "title": "key-value",
    "img": "key-value.png",
    "description": "Data stores are ubiquitous, supporting petabyte data services such as Google and Facebook. Data stores locate large amounts of data, respond to various application data-queries, and react to any data-updates from the application side. Decades of research efforts have been devoted to improving the performances of queries and updates in data stores, reaching a consensus that there exists no static parameter settings that perform well for all query and update workloads. A traditional solution is to involve human (called Database Admins) to timely tune the data stores. Nevertheless, this solution is vulnerable and inefficient. Many database admins spend nearly 25% of their time on tuning but half of the total cost of a data store goes into personnel. If the data stores could automatically optimize themselves without human intervention, then the system deployment cost would be significantly reduced. This project aims to design and develop the next-generation data stores, called autonomous data stores, that can automatically tune itself in reaction to the changes of environment (e.g., with various data distribution, workload characteristics, and resources). Different from previous research, our focus is on the key-value data store, which increasingly serves as the backbone of many real-world big data applications."
  },
  {
    "title": "graph",
    "img": "graph.png",
    "description": "Graphs are among the most widely used data representations, supporting diverse applications such as social networks, transportation systems, biological PPI networks, chemical molecular structures, vision graphs, and financial transaction networks. In today's world, graph data often reaches scales of billions of edges. As a result, the need for scalable algorithms to efficiently process these large graphs has become increasingly urgent and inevitable. This project tackles scalable graph computation problem, aiming to achieve ultra-fast graph algorithms with minimum computation resources for a variety of graph-related problems. These include graph learning, fundamental graph algorithms, graph computation theory and graph database systems."
  },
  {
    "title": "llm",
    "img": "key-value.png",
    "description": "This project aims to develop and apply Large Language Models (LLMs) to advance natural language understanding and generation. Leveraging state-of-the-art architectures like GPT-4, the project focuses on optimizing LLMs for performance, accuracy, and efficiency. Key objectives include enhancing model training techniques, improving contextual understanding, and minimizing biases. The project will explore diverse applications such as automated content creation, customer support automation, and advanced language translation. By creating user-friendly interfaces and robust APIs, the project seeks to make LLM capabilities accessible to various industries, facilitating innovation in communication, education, and business operations. The end goal is to push the boundaries of what LLMs can achieve, providing powerful tools for natural language processing tasks and driving forward the field of artificial intelligence."
  }
]