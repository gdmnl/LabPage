[
  {
    "title": "key-value",
    "img": "key-value.png",
    "description": "Data stores are ubiquitous, supporting petabyte data services such as Google and Facebook. Data stores locate large amounts of data, respond to various application data-queries, and react to any data-updates from the application side. Decades of research efforts have been devoted to improving the performances of queries and updates in data stores, reaching a consensus that there exists no static parameter settings that perform well for all query and update workloads. A traditional solution is to involve human (called Database Admins) to timely tune the data stores. Nevertheless, this solution is vulnerable and inefficient. Many database admins spend nearly 25% of their time on tuning but half of the total cost of a data store goes into personnel. If the data stores could automatically optimize themselves without human intervention, then the system deployment cost would be significantly reduced. This project aims to design and develop the next-generation data stores, called autonomous data stores, that can automatically tune itself in reaction to the changes of environment (e.g., with various data distribution, workload characteristics, and resources). Different from previous research, our focus is on the key-value data store, which increasingly serves as the backbone of many real-world big data applications."
  },
  {
    "title": "graph",
    "img": "graph.png",
    "description": "Graphs are one of the most commonly used data representations, supporting applications in areas like social networks, transportation systems, biological PPI networks, chemical molecules, vision graphs, and financial transaction networks. With real-world graph data now often reaching billions of edges, the need for scalable algorithms to efficiently process these large graphs has become both urgent and unavoidable. However, it is always extremely challenging to scale up the computation due to the inherent difficulty and sophistication of graph structured data. Our team, along with collaborators, is focused on addressing the challenge of scalable graph computation. We aim to develop innovative graph algorithms to achieve low computation complexities, so that the graph algorithms can run over billion-edge graphs with reasonable resources. We target a range of graph-related problems including graph learning, fundamental graph algorithms, graph computation theory, and graph database systems."
  },
  {
    "title": "llm",
    "img": "key-value.png",
    "description": "This project aims to develop and apply Large Language Models (LLMs) to advance natural language understanding and generation. Leveraging state-of-the-art architectures like GPT-4, the project focuses on optimizing LLMs for performance, accuracy, and efficiency. Key objectives include enhancing model training techniques, improving contextual understanding, and minimizing biases. The project will explore diverse applications such as automated content creation, customer support automation, and advanced language translation. By creating user-friendly interfaces and robust APIs, the project seeks to make LLM capabilities accessible to various industries, facilitating innovation in communication, education, and business operations. The end goal is to push the boundaries of what LLMs can achieve, providing powerful tools for natural language processing tasks and driving forward the field of artificial intelligence."
  }
]